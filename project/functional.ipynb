{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85daedee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_df_by_target(df, target_name):\n",
    "\n",
    "    num_0 = len(df[df[target_name]==0])\n",
    "    num_1 = len(df[df[target_name]==1])\n",
    "    undersampled_data = pd.concat([df[df[target_name]==0].sample(num_1), df[df[target_name]==1]])\n",
    "    \n",
    "    return undersampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1509d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(estimator, X, y, params_grid, scoring='f1'):\n",
    "    gsc = GridSearchCV(estimator, params_grid, scoring=scoring, cv=3, n_jobs=-1)\n",
    "\n",
    "    gsc.fit(X, y)\n",
    "    print(\"Best %s score: %.2f\" % (scoring, gsc.best_score_))\n",
    "    print()\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(gsc.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "\n",
    "    for i, params in enumerate(gsc.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (gsc.cv_results_['mean_test_score'][i], gsc.cv_results_['std_test_score'][i] * 2, params))\n",
    "\n",
    "    print()\n",
    "    \n",
    "    return gsc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c0ef20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treshold_search(y_true, y_pred):\n",
    "    top = [0.5, f1_score(y_true, y_pred[: , 1] > 0.5, average='macro')]\n",
    "    for treshold in np.linspace(0, 1, 20):         \n",
    "        fscore = f1_score(y_true, y_pred[: , 1] > treshold, average='macro')\n",
    "        if fscore > top[1]:\n",
    "            top[0] = treshold\n",
    "            top[1] = fscore\n",
    "    print(f'Лучшая отсечка : {top[0]}, Метрика F1_macro: {top[1]}')\n",
    "    print(\"=\" * 80)\n",
    "    print(classification_report(y_true, y_pred[:, 1] > top[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f482aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_train(prep_data_df, FEATURES_DATA):\n",
    "    prep_data_df['buy_time'] = pd.to_datetime(prep_data_df['buy_time'], unit='s')\n",
    "    prep_data_df = prep_data_df.drop('Unnamed: 0', axis=1)\n",
    "    prep_data_df['monthday'] = prep_data_df['buy_time'].dt.day\n",
    "    prep_data_df = prep_data_df.sort_values('buy_time')\n",
    "    prep_data_df['not_first_offer'] = prep_data_df.duplicated('id').astype(int)\n",
    "    \n",
    "    features_data_df = dd.read_csv(FEATURES_DATA, sep='\\t')\n",
    "    features_data_df = features_data_df.drop('Unnamed: 0', axis=1)\n",
    "    train_list_index = list(prep_data_df['id'].unique())\n",
    "    features_data_df = features_data_df.loc[features_data_df['id'].isin(train_list_index)].compute()\n",
    "    features_data_df['buy_time'] = pd.to_datetime(features_data_df['buy_time'], unit='s')\n",
    "    features_data_df = features_data_df.sort_values(by=\"buy_time\")\n",
    "    \n",
    "    result_data = pd.merge_asof(prep_data_df, features_data_df, on='buy_time', by='id', direction='nearest')\n",
    "    \n",
    "    result_data.drop(['id', 'buy_time'], axis=1, inplace=True)\n",
    "    result_data.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return result_data, train_list_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_test(prep_data_df, FEATURES_DATA, train_list_index):\n",
    "    prep_data_df['buy_time'] = pd.to_datetime(prep_data_df['buy_time'], unit='s')\n",
    "    prep_data_df = prep_data_df.drop('Unnamed: 0', axis=1)\n",
    "    prep_data_df['monthday'] = prep_data_df['buy_time'].dt.day\n",
    "    prep_data_df = prep_data_df.sort_values('buy_time')\n",
    "    prep_data_df['not_first_offer'] = (prep_data_df['id'].isin(train_list_index)).astype(int)\n",
    "    \n",
    "    features_data_df = dd.read_csv(FEATURES_DATA, sep='\\t')\n",
    "    features_data_df = features_data_df.drop('Unnamed: 0', axis=1)\n",
    "    test_list_index = list(prep_data_df['id'].unique())\n",
    "    features_data_df = features_data_df.loc[features_data_df['id'].isin(test_list_index)].compute()\n",
    "    features_data_df['buy_time'] = pd.to_datetime(features_data_df['buy_time'], unit='s')\n",
    "    features_data_df = features_data_df.sort_values(by=\"buy_time\")\n",
    "    \n",
    "    result_data = pd.merge_asof(prep_data_df, features_data_df, on='buy_time', by='id', direction='nearest')\n",
    "    \n",
    "    result_data.drop(['id', 'buy_time'], axis=1, inplace=True)\n",
    "    result_data.sort_index(inplace=True)\n",
    "    \n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c178393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_type_cols(merged_data):\n",
    "    \n",
    "    X_nunique = merged_data.apply(lambda x: x.nunique(dropna=False))\n",
    "    f_all = set(X_nunique.index.tolist())\n",
    "    f_const = set(X_nunique[X_nunique == 1].index.tolist())\n",
    "    f_categorical = set(X_nunique[X_nunique <= 30].index.tolist())\n",
    "    f_numeric = (merged_data.fillna(0).astype(int).sum() - merged_data.fillna(0).sum()).abs()\n",
    "    f_numeric = set(f_numeric[f_numeric > 0].index.tolist())\n",
    "    f_binary = set(merged_data.loc[:, f_all].columns[(\n",
    "                      (merged_data.loc[:, f_all].max() == 1) & \\\n",
    "                      (merged_data.loc[:, f_all].min() == 0) & \\\n",
    "                      (merged_data.loc[:, f_all].isnull().sum() == 0))])\n",
    "    f_categorical = f_categorical - f_const - f_binary\n",
    "    f_numeric = f_numeric - f_categorical - f_const\n",
    "    \n",
    "    assert(X_nunique.shape[0] == len(f_const) + len(f_binary) + len(f_numeric) + len(f_categorical))\n",
    "    \n",
    "    f_all = list(f_binary | f_categorical | f_numeric)\n",
    "    f_binary, f_categorical, f_numeric = list(f_binary), list(f_categorical), list(f_numeric)\n",
    "    \n",
    "    return f_all, f_binary, f_categorical, f_numeric\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c2823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9de052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "\n",
    "        try:\n",
    "            return X[self.columns]\n",
    "        except KeyError:\n",
    "            cols_error = list(set(self.columns) - set(X.columns))\n",
    "            raise KeyError(\"DataFrame не содердит следующие колонки: %s\" % cols_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
